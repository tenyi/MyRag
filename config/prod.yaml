# Chinese GraphRAG 生產環境配置
# 適用於生產部署

encoding_model: "cl100k_base"

models:
  # 生產 LLM 模型
  prod_llm:
    type: "openai_chat"
    model: "gpt-4o"
    api_key: "${GRAPHRAG_API_KEY}"
    max_tokens: 4000
    temperature: 0.0
    timeout: 120
    retry_attempts: 5

  # 備用 LLM 模型
  backup_llm:
    type: "openai_chat"
    model: "gpt-4o-mini"
    api_key: "${GRAPHRAG_API_KEY}"
    max_tokens: 2000
    temperature: 0.0

  # 中文 Embedding 模型
  chinese_embedding:
    type: "bge_m3"
    model: "BAAI/bge-m3"
    device: "cuda"
    batch_size: 64
    normalize_embeddings: true

vector_store:
  type: "lancedb"
  uri: "/data/graphrag/lancedb"
  container_name: "prod_graphrag"
  overwrite: false
  metric: "cosine"

chinese_processing:
  tokenizer: "jieba"
  enable_traditional_chinese: true
  enable_pos_tagging: true

input:
  base_dir: "/data/input"
  supported_formats: ["txt", "pdf", "docx", "md"]
  recursive: true

chunks:
  size: 1200
  overlap: 240

indexing:
  enable_entity_extraction: true
  enable_relationship_extraction: true
  enable_community_detection: true
  enable_community_reports: true
  min_community_size: 5
  max_community_size: 100
  max_gleanings: 2

query:
  enable_global_search: true
  enable_local_search: true
  max_tokens: 4000
  top_k: 20
  similarity_threshold: 0.8

storage:
  base_dir: "/data/output"
  cache_dir: "/data/cache"
  logs_dir: "/logs"

parallelization:
  num_threads: 8
  batch_size: 20
  max_concurrent_requests: 50

model_selection:
  default_llm: "prod_llm"
  default_embedding: "chinese_embedding"
  cost_optimization: false
  quality_threshold: 0.9
  fallback_models:
    prod_llm: "backup_llm"

logging:
  level: "INFO"
  enable_console: false
  enable_file: true
  enable_json: true
  max_file_size: 52428800  # 50MB
  backup_count: 10

monitoring:
  enable_metrics: true
  metrics_port: 8000
  enable_health_check: true
  enable_performance_tracking: true
  slow_query_threshold: 60.0
  enable_error_tracking: true

performance:
  enable_caching: true
  cache_ttl: 7200  # 2小時
  memory_limit_mb: 8192
  enable_gpu_acceleration: true

security:
  enable_api_key_validation: true
  rate_limit_requests_per_minute: 1000
  enable_request_logging: true

debug:
  enable_debug_mode: false
  save_intermediate_results: false
  verbose_logging: false