#!/usr/bin/env python3
"""
æ•ˆèƒ½å„ªåŒ–ç³»çµ±é©—è­‰è…³æœ¬

é©—è­‰æ‰€æœ‰æ•ˆèƒ½å„ªåŒ–æ¨¡çµ„çš„åŸºæœ¬åŠŸèƒ½
"""

import asyncio
import sys
import tempfile
import time
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from src.chinese_graphrag.performance import (
        OptimizerManager,
        OptimizationConfig,
        BatchOptimizer,
        QueryOptimizer,
        CostOptimizer,
        PerformanceMonitor,
        BenchmarkRunner,
        ConfigLoader,
        load_performance_config
    )
    print("âœ… æ‰€æœ‰æ¨¡çµ„åŒ¯å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ æ¨¡çµ„åŒ¯å…¥å¤±æ•—: {e}")
    sys.exit(1)


async def test_batch_optimizer():
    """æ¸¬è©¦æ‰¹æ¬¡å„ªåŒ–å™¨"""
    print("\nğŸ”„ æ¸¬è©¦æ‰¹æ¬¡å„ªåŒ–å™¨...")
    
    try:
        optimizer = BatchOptimizer(
            default_batch_size=8,
            max_batch_size=32,
            parallel_workers=2
        )
        
        # æ¨¡æ“¬è™•ç†å‡½æ•¸
        async def mock_process(item):
            await asyncio.sleep(0.01)
            return f"processed_{item}"
        
        # æ¸¬è©¦æ‰¹æ¬¡è™•ç†
        test_items = list(range(20))
        results = await optimizer.process_batch(test_items, mock_process)
        
        assert len(results) == len(test_items)
        print("âœ… æ‰¹æ¬¡å„ªåŒ–å™¨æ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ æ‰¹æ¬¡å„ªåŒ–å™¨æ¸¬è©¦å¤±æ•—: {e}")
        return False


async def test_query_optimizer():
    """æ¸¬è©¦æŸ¥è©¢å„ªåŒ–å™¨"""
    print("\nğŸ” æ¸¬è©¦æŸ¥è©¢å„ªåŒ–å™¨...")
    
    try:
        optimizer = QueryOptimizer(
            cache_ttl=300,
            max_cache_size=100
        )
        
        # æ¨¡æ“¬æŸ¥è©¢å‡½æ•¸
        call_count = 0
        async def mock_query(query):
            nonlocal call_count
            call_count += 1
            await asyncio.sleep(0.05)
            return f"result_for_{query}"
        
        query = "test_query"
        
        # ç¬¬ä¸€æ¬¡æŸ¥è©¢
        result1 = await optimizer.get_cached_result(query)
        if result1 is None:
            result1 = await mock_query(query)
            await optimizer.cache_result(query, result1)
        
        # ç¬¬äºŒæ¬¡æŸ¥è©¢ï¼ˆæ‡‰è©²å¾å¿«å–å–å¾—ï¼‰
        result2 = await optimizer.get_cached_result(query)
        
        assert result1 == result2
        assert result2 is not None
        print("âœ… æŸ¥è©¢å„ªåŒ–å™¨æ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ æŸ¥è©¢å„ªåŒ–å™¨æ¸¬è©¦å¤±æ•—: {e}")
        return False


async def test_cost_optimizer():
    """æ¸¬è©¦æˆæœ¬å„ªåŒ–å™¨"""
    print("\nğŸ’° æ¸¬è©¦æˆæœ¬å„ªåŒ–å™¨...")
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            optimizer = CostOptimizer(
                budget_limit=10.0,
                quality_threshold=0.8,
                storage_path=str(Path(temp_dir) / "cost_tracking.json")
            )
            
            # æ¸¬è©¦ä½¿ç”¨è¿½è¹¤
            await optimizer.track_usage(
                model_name="test-model",
                input_tokens=100,
                output_tokens=50,
                operation_type="test"
            )
            
            # æ¸¬è©¦çµ±è¨ˆ
            stats = optimizer.get_usage_stats(60)
            assert "total_cost" in stats
            
            print("âœ… æˆæœ¬å„ªåŒ–å™¨æ¸¬è©¦é€šé")
            return True
            
    except Exception as e:
        print(f"âŒ æˆæœ¬å„ªåŒ–å™¨æ¸¬è©¦å¤±æ•—: {e}")
        return False


async def test_performance_monitor():
    """æ¸¬è©¦æ•ˆèƒ½ç›£æ§å™¨"""
    print("\nğŸ“ˆ æ¸¬è©¦æ•ˆèƒ½ç›£æ§å™¨...")
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            monitor = PerformanceMonitor(
                collection_interval=1.0,
                history_size=10,
                storage_path=temp_dir
            )
            
            # å•Ÿå‹•ç›£æ§
            monitor.start_monitoring()
            
            # ç­‰å¾…æ”¶é›†ä¸€äº›è³‡æ–™
            await asyncio.sleep(2.5)
            
            # æª¢æŸ¥è³‡æ–™
            current_metrics = monitor.get_current_metrics()
            assert current_metrics is not None
            assert current_metrics.cpu_usage >= 0
            
            # åœæ­¢ç›£æ§
            monitor.stop_monitoring()
            
            print("âœ… æ•ˆèƒ½ç›£æ§å™¨æ¸¬è©¦é€šé")
            return True
            
    except Exception as e:
        print(f"âŒ æ•ˆèƒ½ç›£æ§å™¨æ¸¬è©¦å¤±æ•—: {e}")
        return False


async def test_benchmark_runner():
    """æ¸¬è©¦åŸºæº–æ¸¬è©¦åŸ·è¡Œå™¨"""
    print("\nğŸ æ¸¬è©¦åŸºæº–æ¸¬è©¦åŸ·è¡Œå™¨...")
    
    try:
        runner = BenchmarkRunner()
        
        # å®šç¾©æ¸¬è©¦å‡½æ•¸
        async def test_function():
            await asyncio.sleep(0.01)
            return "test_result"
        
        # åŸ·è¡ŒåŸºæº–æ¸¬è©¦
        result = await runner.run_benchmark(
            test_name="simple_test",
            test_func=test_function,
            test_params={},
            iterations=3
        )
        
        assert result.test_name == "simple_test"
        assert result.total_operations == 3
        assert result.throughput > 0
        
        print("âœ… åŸºæº–æ¸¬è©¦åŸ·è¡Œå™¨æ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ åŸºæº–æ¸¬è©¦åŸ·è¡Œå™¨æ¸¬è©¦å¤±æ•—: {e}")
        return False


async def test_optimizer_manager():
    """æ¸¬è©¦å„ªåŒ–ç®¡ç†å™¨"""
    print("\nğŸ¯ æ¸¬è©¦å„ªåŒ–ç®¡ç†å™¨...")
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            config = OptimizationConfig(
                batch_enabled=True,
                batch_size=8,
                parallel_workers=2,
                query_cache_enabled=True,
                cache_ttl_seconds=300,
                cost_tracking_enabled=True,
                budget_limit_usd=10.0,
                monitoring_enabled=True,
                monitoring_interval=2.0,
                storage_path=temp_dir
            )
            
            async with OptimizerManager(config) as manager:
                # æ¸¬è©¦æ‰¹æ¬¡è™•ç†
                async def mock_process(item):
                    return f"item_{item}"
                
                results = await manager.optimize_batch_processing(
                    items=[1, 2, 3],
                    process_func=mock_process
                )
                assert len(results) == 3
                
                # æ¸¬è©¦æŸ¥è©¢å„ªåŒ–
                async def mock_query(query):
                    return f"result_{query}"
                
                result = await manager.optimize_query(
                    query="test",
                    query_func=mock_query
                )
                assert result == "result_test"
                
                # æ¸¬è©¦ç‹€æ…‹
                status = manager.get_performance_status()
                assert status["initialized"]
                assert status["running"]
                
                print("âœ… å„ªåŒ–ç®¡ç†å™¨æ¸¬è©¦é€šé")
                return True
                
    except Exception as e:
        print(f"âŒ å„ªåŒ–ç®¡ç†å™¨æ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_config_loader():
    """æ¸¬è©¦é…ç½®è¼‰å…¥å™¨"""
    print("\nâš™ï¸ æ¸¬è©¦é…ç½®è¼‰å…¥å™¨...")
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            # å»ºç«‹æ¸¬è©¦é…ç½®æª”æ¡ˆ
            config_content = """
batch_optimization:
  enabled: true
  default_batch_size: 16
  parallel_workers: 2

query_optimization:
  cache_enabled: true
  cache_ttl_seconds: 600

cost_optimization:
  tracking_enabled: true
  budget_limit_usd: 50.0

performance_monitoring:
  enabled: true
  collection_interval: 5.0

storage:
  base_path: "test_logs"
"""
            
            config_path = Path(temp_dir) / "test_config.yaml"
            with open(config_path, 'w') as f:
                f.write(config_content)
            
            # æ¸¬è©¦è¼‰å…¥é…ç½®
            loader = ConfigLoader(str(config_path), "development")
            config = loader.load_config()
            
            assert config.optimization.batch_enabled
            assert config.optimization.batch_size == 16
            assert config.optimization.parallel_workers == 2
            
            print("âœ… é…ç½®è¼‰å…¥å™¨æ¸¬è©¦é€šé")
            return True
            
    except Exception as e:
        print(f"âŒ é…ç½®è¼‰å…¥å™¨æ¸¬è©¦å¤±æ•—: {e}")
        return False


async def run_all_tests():
    """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
    print("ğŸš€ é–‹å§‹æ•ˆèƒ½å„ªåŒ–ç³»çµ±é©—è­‰")
    print("=" * 50)
    
    tests = [
        test_batch_optimizer,
        test_query_optimizer,
        test_cost_optimizer,
        test_performance_monitor,
        test_benchmark_runner,
        test_optimizer_manager,
    ]
    
    sync_tests = [
        test_config_loader,
    ]
    
    passed = 0
    total = len(tests) + len(sync_tests)
    
    # åŸ·è¡Œç•°æ­¥æ¸¬è©¦
    for test in tests:
        try:
            if await test():
                passed += 1
        except Exception as e:
            print(f"âŒ æ¸¬è©¦åŸ·è¡ŒéŒ¯èª¤: {e}")
    
    # åŸ·è¡ŒåŒæ­¥æ¸¬è©¦
    for test in sync_tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"âŒ æ¸¬è©¦åŸ·è¡ŒéŒ¯èª¤: {e}")
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š æ¸¬è©¦çµæœ: {passed}/{total} é€šé")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼æ•ˆèƒ½å„ªåŒ–ç³»çµ±é©—è­‰æˆåŠŸ")
        return True
    else:
        print(f"âš ï¸  æœ‰ {total - passed} å€‹æ¸¬è©¦å¤±æ•—")
        return False


def main():
    """ä¸»å‡½æ•¸"""
    try:
        success = asyncio.run(run_all_tests())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æ¸¬è©¦è¢«ä¸­æ–·")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()