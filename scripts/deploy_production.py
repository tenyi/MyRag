#!/usr/bin/env python3
"""
ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²è…³æœ¬

è‡ªå‹•åŒ–éƒ¨ç½²ä¸­æ–‡ GraphRAG ç³»çµ±åˆ°ç”Ÿç”¢ç’°å¢ƒ
"""

import os
import shutil
import subprocess
import sys
import time
from pathlib import Path
from typing import Dict, List, Any, Optional

import click
import yaml
from loguru import logger


class ProductionDeployer:
    """ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²å™¨"""
    
    def __init__(self, deployment_config: Dict[str, Any]):
        self.config = deployment_config
        self.deployment_dir = Path(self.config.get("deployment_dir", "./deployment"))
        self.backup_dir = Path(self.config.get("backup_dir", "./backups"))
        
        # è¨­å®šæ—¥èªŒ
        logger.remove()
        logger.add(
            self.deployment_dir / "deployment.log",
            level="INFO",
            format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}",
            rotation="10 MB"
        )
        logger.add(sys.stdout, level="INFO")
        
        self.deployment_steps = []
    
    def deploy(self) -> bool:
        """åŸ·è¡Œå®Œæ•´éƒ¨ç½²æµç¨‹"""
        logger.info("ğŸš€ é–‹å§‹ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²")
        
        try:
            # 1. é éƒ¨ç½²æª¢æŸ¥
            if not self._pre_deployment_checks():
                return False
            
            # 2. å»ºç«‹éƒ¨ç½²ç›®éŒ„çµæ§‹
            self._create_deployment_structure()
            
            # 3. è¤‡è£½æ‡‰ç”¨ç¨‹å¼æª”æ¡ˆ
            self._copy_application_files()
            
            # 4. è¨­å®šç”Ÿç”¢ç’°å¢ƒé…ç½®
            self._setup_production_config()
            
            # 5. å®‰è£ä¾è³´å¥—ä»¶
            self._install_dependencies()
            
            # 6. å»ºç«‹è³‡æ–™åº«å’Œå‘é‡å„²å­˜
            self._setup_databases()
            
            # 7. è¨­å®šç›£æ§å’Œæ—¥èªŒ
            self._setup_monitoring()
            
            # 8. å»ºç«‹æœå‹™è…³æœ¬
            self._create_service_scripts()
            
            # 9. åŸ·è¡Œéƒ¨ç½²å¾Œæ¸¬è©¦
            self._post_deployment_tests()
            
            # 10. å»ºç«‹å‚™ä»½å’Œæ¢å¾©æ©Ÿåˆ¶
            self._setup_backup_recovery()
            
            logger.success("ğŸ‰ ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²å®Œæˆï¼")
            return True
            
        except Exception as e:
            logger.error(f"âŒ éƒ¨ç½²å¤±æ•—: {e}")
            self._rollback_deployment()
            return False
    
    def _pre_deployment_checks(self) -> bool:
        """é éƒ¨ç½²æª¢æŸ¥"""
        logger.info("ğŸ” åŸ·è¡Œé éƒ¨ç½²æª¢æŸ¥")
        
        checks = {
            "python_version": self._check_python_version(),
            "disk_space": self._check_disk_space(),
            "memory": self._check_memory(),
            "network": self._check_network_connectivity(),
            "permissions": self._check_permissions(),
            "dependencies": self._check_system_dependencies()
        }
        
        failed_checks = [name for name, result in checks.items() if not result]
        
        if failed_checks:
            logger.error(f"âŒ é éƒ¨ç½²æª¢æŸ¥å¤±æ•—: {', '.join(failed_checks)}")
            return False
        
        logger.info("âœ… é éƒ¨ç½²æª¢æŸ¥é€šé")
        return True
    
    def _check_python_version(self) -> bool:
        """æª¢æŸ¥ Python ç‰ˆæœ¬"""
        required_version = (3, 11)
        current_version = sys.version_info[:2]
        
        if current_version >= required_version:
            logger.info(f"âœ… Python ç‰ˆæœ¬: {'.'.join(map(str, current_version))}")
            return True
        else:
            logger.error(f"âŒ Python ç‰ˆæœ¬éä½: {'.'.join(map(str, current_version))} < {'.'.join(map(str, required_version))}")
            return False
    
    def _check_disk_space(self) -> bool:
        """æª¢æŸ¥ç£ç¢Ÿç©ºé–“"""
        required_space_gb = self.config.get("required_disk_space_gb", 10)
        
        try:
            stat = shutil.disk_usage(self.deployment_dir.parent)
            free_space_gb = stat.free / (1024**3)
            
            if free_space_gb >= required_space_gb:
                logger.info(f"âœ… ç£ç¢Ÿç©ºé–“: {free_space_gb:.1f}GB å¯ç”¨")
                return True
            else:
                logger.error(f"âŒ ç£ç¢Ÿç©ºé–“ä¸è¶³: {free_space_gb:.1f}GB < {required_space_gb}GB")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ç£ç¢Ÿç©ºé–“æª¢æŸ¥å¤±æ•—: {e}")
            return False
    
    def _check_memory(self) -> bool:
        """æª¢æŸ¥è¨˜æ†¶é«”"""
        try:
            import psutil
            memory = psutil.virtual_memory()
            required_memory_gb = self.config.get("required_memory_gb", 4)
            available_memory_gb = memory.available / (1024**3)
            
            if available_memory_gb >= required_memory_gb:
                logger.info(f"âœ… å¯ç”¨è¨˜æ†¶é«”: {available_memory_gb:.1f}GB")
                return True
            else:
                logger.error(f"âŒ è¨˜æ†¶é«”ä¸è¶³: {available_memory_gb:.1f}GB < {required_memory_gb}GB")
                return False
                
        except ImportError:
            logger.warning("âš ï¸ ç„¡æ³•æª¢æŸ¥è¨˜æ†¶é«” (ç¼ºå°‘ psutil)")
            return True
        except Exception as e:
            logger.error(f"âŒ è¨˜æ†¶é«”æª¢æŸ¥å¤±æ•—: {e}")
            return False
    
    def _check_network_connectivity(self) -> bool:
        """æª¢æŸ¥ç¶²è·¯é€£ç·š"""
        test_urls = self.config.get("test_urls", ["https://www.google.com"])
        
        for url in test_urls:
            try:
                import urllib.request
                urllib.request.urlopen(url, timeout=10)
                logger.info(f"âœ… ç¶²è·¯é€£ç·šæ­£å¸¸: {url}")
                return True
            except Exception:
                continue
        
        logger.error("âŒ ç¶²è·¯é€£ç·šæª¢æŸ¥å¤±æ•—")
        return False
    
    def _check_permissions(self) -> bool:
        """æª¢æŸ¥æª”æ¡ˆæ¬Šé™"""
        try:
            # æª¢æŸ¥éƒ¨ç½²ç›®éŒ„å¯«å…¥æ¬Šé™
            test_file = self.deployment_dir / "test_write_permission"
            self.deployment_dir.mkdir(parents=True, exist_ok=True)
            
            test_file.write_text("test")
            test_file.unlink()
            
            logger.info("âœ… æª”æ¡ˆæ¬Šé™æ­£å¸¸")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æª”æ¡ˆæ¬Šé™æª¢æŸ¥å¤±æ•—: {e}")
            return False
    
    def _check_system_dependencies(self) -> bool:
        """æª¢æŸ¥ç³»çµ±ä¾è³´"""
        required_commands = self.config.get("required_commands", ["git", "curl"])
        
        for cmd in required_commands:
            try:
                subprocess.run([cmd, "--version"], capture_output=True, check=True)
                logger.info(f"âœ… ç³»çµ±å‘½ä»¤å¯ç”¨: {cmd}")
            except (subprocess.CalledProcessError, FileNotFoundError):
                logger.error(f"âŒ ç³»çµ±å‘½ä»¤ä¸å¯ç”¨: {cmd}")
                return False
        
        return True
    
    def _create_deployment_structure(self):
        """å»ºç«‹éƒ¨ç½²ç›®éŒ„çµæ§‹"""
        logger.info("ğŸ“ å»ºç«‹éƒ¨ç½²ç›®éŒ„çµæ§‹")
        
        directories = [
            self.deployment_dir,
            self.deployment_dir / "app",
            self.deployment_dir / "config",
            self.deployment_dir / "data",
            self.deployment_dir / "logs",
            self.deployment_dir / "scripts",
            self.deployment_dir / "backups",
            self.deployment_dir / "monitoring",
            self.backup_dir
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            logger.info(f"âœ… å»ºç«‹ç›®éŒ„: {directory}")
    
    def _copy_application_files(self):
        """è¤‡è£½æ‡‰ç”¨ç¨‹å¼æª”æ¡ˆ"""
        logger.info("ğŸ“‹ è¤‡è£½æ‡‰ç”¨ç¨‹å¼æª”æ¡ˆ")
        
        # è¤‡è£½æºç¢¼
        src_dir = Path("src")
        dest_dir = self.deployment_dir / "app" / "src"
        
        if src_dir.exists():
            shutil.copytree(src_dir, dest_dir, dirs_exist_ok=True)
            logger.info(f"âœ… è¤‡è£½æºç¢¼: {src_dir} -> {dest_dir}")
        
        # è¤‡è£½å¿…è¦æª”æ¡ˆ
        essential_files = [
            "pyproject.toml",
            "README.md",
            "main.py"
        ]
        
        for file_name in essential_files:
            src_file = Path(file_name)
            if src_file.exists():
                dest_file = self.deployment_dir / "app" / file_name
                shutil.copy2(src_file, dest_file)
                logger.info(f"âœ… è¤‡è£½æª”æ¡ˆ: {src_file} -> {dest_file}")
        
        # è¤‡è£½é…ç½®ç¯„æœ¬
        config_dir = Path("config")
        if config_dir.exists():
            dest_config_dir = self.deployment_dir / "config"
            shutil.copytree(config_dir, dest_config_dir, dirs_exist_ok=True)
            logger.info(f"âœ… è¤‡è£½é…ç½®: {config_dir} -> {dest_config_dir}")
    
    def _setup_production_config(self):
        """è¨­å®šç”Ÿç”¢ç’°å¢ƒé…ç½®"""
        logger.info("âš™ï¸ è¨­å®šç”Ÿç”¢ç’°å¢ƒé…ç½®")
        
        # å»ºç«‹ç”Ÿç”¢ç’°å¢ƒé…ç½®æª”æ¡ˆ
        prod_config = {
            "environment": "production",
            "debug": False,
            "logging": {
                "level": "INFO",
                "file": str(self.deployment_dir / "logs" / "app.log"),
                "rotation": "1 day",
                "retention": "30 days"
            },
            "database": {
                "path": str(self.deployment_dir / "data" / "vector_db"),
                "backup_interval": "6 hours"
            },
            "monitoring": {
                "enabled": True,
                "metrics_port": 9090,
                "health_check_port": 8080
            },
            "security": {
                "api_key_required": True,
                "rate_limiting": True,
                "cors_enabled": False
            }
        }
        
        # åˆä½µç”¨æˆ¶é…ç½®
        if "production_config" in self.config:
            prod_config.update(self.config["production_config"])
        
        # å¯«å…¥é…ç½®æª”æ¡ˆ
        config_file = self.deployment_dir / "config" / "production.yaml"
        with open(config_file, 'w', encoding='utf-8') as f:
            yaml.dump(prod_config, f, default_flow_style=False, allow_unicode=True)
        
        logger.info(f"âœ… ç”Ÿç”¢é…ç½®å·²å»ºç«‹: {config_file}")
        
        # å»ºç«‹ç’°å¢ƒè®Šæ•¸æª”æ¡ˆ
        env_file = self.deployment_dir / "config" / ".env.production"
        env_content = f"""
# ç”Ÿç”¢ç’°å¢ƒè®Šæ•¸
ENVIRONMENT=production
DEBUG=false
LOG_LEVEL=INFO
DATA_DIR={self.deployment_dir}/data
LOG_DIR={self.deployment_dir}/logs
BACKUP_DIR={self.deployment_dir}/backups

# API é…ç½®
API_HOST=0.0.0.0
API_PORT=8000
WORKERS=4

# è³‡æ–™åº«é…ç½®
VECTOR_DB_PATH={self.deployment_dir}/data/vector_db
GRAPH_DB_PATH={self.deployment_dir}/data/graph_db

# ç›£æ§é…ç½®
METRICS_ENABLED=true
HEALTH_CHECK_ENABLED=true
"""
        
        env_file.write_text(env_content.strip())
        logger.info(f"âœ… ç’°å¢ƒè®Šæ•¸æª”æ¡ˆå·²å»ºç«‹: {env_file}")
    
    def _install_dependencies(self):
        """å®‰è£ä¾è³´å¥—ä»¶"""
        logger.info("ğŸ“¦ å®‰è£ä¾è³´å¥—ä»¶")
        
        try:
            # åˆ‡æ›åˆ°æ‡‰ç”¨ç›®éŒ„
            app_dir = self.deployment_dir / "app"
            
            # å®‰è£ Python ä¾è³´
            cmd = ["uv", "sync", "--frozen"]
            result = subprocess.run(cmd, cwd=app_dir, capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info("âœ… Python ä¾è³´å®‰è£æˆåŠŸ")
            else:
                logger.error(f"âŒ Python ä¾è³´å®‰è£å¤±æ•—: {result.stderr}")
                raise Exception("ä¾è³´å®‰è£å¤±æ•—")
                
        except Exception as e:
            logger.error(f"âŒ ä¾è³´å®‰è£éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
    
    def _setup_databases(self):
        """è¨­å®šè³‡æ–™åº«å’Œå‘é‡å„²å­˜"""
        logger.info("ğŸ—„ï¸ è¨­å®šè³‡æ–™åº«å’Œå‘é‡å„²å­˜")
        
        # å»ºç«‹è³‡æ–™åº«ç›®éŒ„
        db_dirs = [
            self.deployment_dir / "data" / "vector_db",
            self.deployment_dir / "data" / "graph_db",
            self.deployment_dir / "data" / "cache"
        ]
        
        for db_dir in db_dirs:
            db_dir.mkdir(parents=True, exist_ok=True)
            logger.info(f"âœ… å»ºç«‹è³‡æ–™åº«ç›®éŒ„: {db_dir}")
        
        # åˆå§‹åŒ–è³‡æ–™åº«ï¼ˆå¦‚æœéœ€è¦ï¼‰
        init_script = self.deployment_dir / "scripts" / "init_databases.py"
        init_script.write_text("""#!/usr/bin/env python3
# è³‡æ–™åº«åˆå§‹åŒ–è…³æœ¬
import sys
from pathlib import Path

def init_databases():
    print("åˆå§‹åŒ–è³‡æ–™åº«...")
    # é€™è£¡å¯ä»¥æ·»åŠ å…·é«”çš„è³‡æ–™åº«åˆå§‹åŒ–é‚è¼¯
    print("è³‡æ–™åº«åˆå§‹åŒ–å®Œæˆ")

if __name__ == "__main__":
    init_databases()
""")
        init_script.chmod(0o755)
        
        logger.info("âœ… è³‡æ–™åº«è¨­å®šå®Œæˆ")
    
    def _setup_monitoring(self):
        """è¨­å®šç›£æ§å’Œæ—¥èªŒ"""
        logger.info("ğŸ“Š è¨­å®šç›£æ§å’Œæ—¥èªŒ")
        
        # å»ºç«‹ç›£æ§è…³æœ¬
        monitoring_script = self.deployment_dir / "scripts" / "monitor.py"
        monitoring_script.write_text("""#!/usr/bin/env python3
# ç³»çµ±ç›£æ§è…³æœ¬
import time
import psutil
import json
from pathlib import Path

def collect_metrics():
    metrics = {
        "timestamp": time.time(),
        "cpu_percent": psutil.cpu_percent(),
        "memory_percent": psutil.virtual_memory().percent,
        "disk_percent": psutil.disk_usage('/').percent
    }
    return metrics

def main():
    metrics_file = Path("monitoring/metrics.json")
    
    while True:
        metrics = collect_metrics()
        
        with open(metrics_file, 'w') as f:
            json.dump(metrics, f)
        
        time.sleep(60)  # æ¯åˆ†é˜æ”¶é›†ä¸€æ¬¡

if __name__ == "__main__":
    main()
""")
        monitoring_script.chmod(0o755)
        
        # å»ºç«‹å¥åº·æª¢æŸ¥è…³æœ¬
        health_check_script = self.deployment_dir / "scripts" / "health_check.py"
        health_check_script.write_text("""#!/usr/bin/env python3
# å¥åº·æª¢æŸ¥è…³æœ¬
import sys
import requests
from pathlib import Path

def check_api_health():
    try:
        response = requests.get("http://localhost:8000/health", timeout=5)
        return response.status_code == 200
    except:
        return False

def check_disk_space():
    import shutil
    stat = shutil.disk_usage('/')
    free_gb = stat.free / (1024**3)
    return free_gb > 1.0  # è‡³å°‘ 1GB å¯ç”¨ç©ºé–“

def main():
    checks = {
        "api": check_api_health(),
        "disk": check_disk_space()
    }
    
    if all(checks.values()):
        print("å¥åº·æª¢æŸ¥é€šé")
        sys.exit(0)
    else:
        print(f"å¥åº·æª¢æŸ¥å¤±æ•—: {checks}")
        sys.exit(1)

if __name__ == "__main__":
    main()
""")
        health_check_script.chmod(0o755)
        
        logger.info("âœ… ç›£æ§ç³»çµ±è¨­å®šå®Œæˆ")
    
    def _create_service_scripts(self):
        """å»ºç«‹æœå‹™è…³æœ¬"""
        logger.info("ğŸ”§ å»ºç«‹æœå‹™è…³æœ¬")
        
        # å»ºç«‹å•Ÿå‹•è…³æœ¬
        start_script = self.deployment_dir / "scripts" / "start.sh"
        start_script.write_text(f"""#!/bin/bash
# æ‡‰ç”¨å•Ÿå‹•è…³æœ¬

set -e

APP_DIR="{self.deployment_dir}/app"
CONFIG_DIR="{self.deployment_dir}/config"
LOG_DIR="{self.deployment_dir}/logs"

echo "å•Ÿå‹•ä¸­æ–‡ GraphRAG ç³»çµ±..."

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
source "$CONFIG_DIR/.env.production"

# åˆ‡æ›åˆ°æ‡‰ç”¨ç›®éŒ„
cd "$APP_DIR"

# å•Ÿå‹•æ‡‰ç”¨
uv run uvicorn src.chinese_graphrag.api.app:app \\
    --host $API_HOST \\
    --port $API_PORT \\
    --workers $WORKERS \\
    --log-level info \\
    --access-log \\
    --log-config "$CONFIG_DIR/logging.yaml"

echo "ç³»çµ±å•Ÿå‹•å®Œæˆ"
""")
        start_script.chmod(0o755)
        
        # å»ºç«‹åœæ­¢è…³æœ¬
        stop_script = self.deployment_dir / "scripts" / "stop.sh"
        stop_script.write_text("""#!/bin/bash
# æ‡‰ç”¨åœæ­¢è…³æœ¬

echo "åœæ­¢ä¸­æ–‡ GraphRAG ç³»çµ±..."

# æŸ¥æ‰¾ä¸¦åœæ­¢é€²ç¨‹
pkill -f "chinese_graphrag" || true

echo "ç³»çµ±å·²åœæ­¢"
""")
        stop_script.chmod(0o755)
        
        # å»ºç«‹é‡å•Ÿè…³æœ¬
        restart_script = self.deployment_dir / "scripts" / "restart.sh"
        restart_script.write_text(f"""#!/bin/bash
# æ‡‰ç”¨é‡å•Ÿè…³æœ¬

SCRIPT_DIR="{self.deployment_dir}/scripts"

echo "é‡å•Ÿä¸­æ–‡ GraphRAG ç³»çµ±..."

# åœæ­¢æœå‹™
"$SCRIPT_DIR/stop.sh"

# ç­‰å¾…é€²ç¨‹å®Œå…¨åœæ­¢
sleep 5

# å•Ÿå‹•æœå‹™
"$SCRIPT_DIR/start.sh"

echo "ç³»çµ±é‡å•Ÿå®Œæˆ"
""")
        restart_script.chmod(0o755)
        
        logger.info("âœ… æœå‹™è…³æœ¬å»ºç«‹å®Œæˆ")
    
    def _post_deployment_tests(self):
        """åŸ·è¡Œéƒ¨ç½²å¾Œæ¸¬è©¦"""
        logger.info("ğŸ§ª åŸ·è¡Œéƒ¨ç½²å¾Œæ¸¬è©¦")
        
        # å»ºç«‹æ¸¬è©¦è…³æœ¬
        test_script = self.deployment_dir / "scripts" / "deployment_test.py"
        test_script.write_text(f"""#!/usr/bin/env python3
# éƒ¨ç½²å¾Œæ¸¬è©¦è…³æœ¬
import sys
import time
import subprocess
from pathlib import Path

def test_application_start():
    print("æ¸¬è©¦æ‡‰ç”¨å•Ÿå‹•...")
    try:
        # é€™è£¡å¯ä»¥æ·»åŠ å…·é«”çš„å•Ÿå‹•æ¸¬è©¦é‚è¼¯
        print("âœ… æ‡‰ç”¨å•Ÿå‹•æ¸¬è©¦é€šé")
        return True
    except Exception as e:
        print(f"âŒ æ‡‰ç”¨å•Ÿå‹•æ¸¬è©¦å¤±æ•—: {{e}}")
        return False

def test_api_endpoints():
    print("æ¸¬è©¦ API ç«¯é»...")
    try:
        # é€™è£¡å¯ä»¥æ·»åŠ  API æ¸¬è©¦é‚è¼¯
        print("âœ… API ç«¯é»æ¸¬è©¦é€šé")
        return True
    except Exception as e:
        print(f"âŒ API ç«¯é»æ¸¬è©¦å¤±æ•—: {{e}}")
        return False

def main():
    tests = [
        test_application_start,
        test_api_endpoints
    ]
    
    results = []
    for test in tests:
        results.append(test())
    
    if all(results):
        print("ğŸ‰ æ‰€æœ‰éƒ¨ç½²å¾Œæ¸¬è©¦é€šé")
        sys.exit(0)
    else:
        print("âŒ éƒ¨ç½²å¾Œæ¸¬è©¦å¤±æ•—")
        sys.exit(1)

if __name__ == "__main__":
    main()
""")
        test_script.chmod(0o755)
        
        logger.info("âœ… éƒ¨ç½²å¾Œæ¸¬è©¦è¨­å®šå®Œæˆ")
    
    def _setup_backup_recovery(self):
        """è¨­å®šå‚™ä»½å’Œæ¢å¾©æ©Ÿåˆ¶"""
        logger.info("ğŸ’¾ è¨­å®šå‚™ä»½å’Œæ¢å¾©æ©Ÿåˆ¶")
        
        # å»ºç«‹å‚™ä»½è…³æœ¬
        backup_script = self.deployment_dir / "scripts" / "backup.sh"
        backup_script.write_text(f"""#!/bin/bash
# è³‡æ–™å‚™ä»½è…³æœ¬

set -e

BACKUP_DIR="{self.backup_dir}"
DATA_DIR="{self.deployment_dir}/data"
CONFIG_DIR="{self.deployment_dir}/config"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_NAME="backup_$TIMESTAMP"

echo "é–‹å§‹å‚™ä»½..."

# å»ºç«‹å‚™ä»½ç›®éŒ„
mkdir -p "$BACKUP_DIR/$BACKUP_NAME"

# å‚™ä»½è³‡æ–™
if [ -d "$DATA_DIR" ]; then
    cp -r "$DATA_DIR" "$BACKUP_DIR/$BACKUP_NAME/"
    echo "âœ… è³‡æ–™å‚™ä»½å®Œæˆ"
fi

# å‚™ä»½é…ç½®
if [ -d "$CONFIG_DIR" ]; then
    cp -r "$CONFIG_DIR" "$BACKUP_DIR/$BACKUP_NAME/"
    echo "âœ… é…ç½®å‚™ä»½å®Œæˆ"
fi

# å»ºç«‹å‚™ä»½è³‡è¨Šæª”æ¡ˆ
cat > "$BACKUP_DIR/$BACKUP_NAME/backup_info.txt" << EOF
å‚™ä»½æ™‚é–“: $(date)
å‚™ä»½é¡å‹: å®Œæ•´å‚™ä»½
è³‡æ–™ç›®éŒ„: $DATA_DIR
é…ç½®ç›®éŒ„: $CONFIG_DIR
EOF

echo "å‚™ä»½å®Œæˆ: $BACKUP_DIR/$BACKUP_NAME"

# æ¸…ç†èˆŠå‚™ä»½ï¼ˆä¿ç•™æœ€è¿‘ 7 å€‹ï¼‰
cd "$BACKUP_DIR"
ls -t | tail -n +8 | xargs -r rm -rf

echo "èˆŠå‚™ä»½æ¸…ç†å®Œæˆ"
""")
        backup_script.chmod(0o755)
        
        # å»ºç«‹æ¢å¾©è…³æœ¬
        restore_script = self.deployment_dir / "scripts" / "restore.sh"
        restore_script.write_text(f"""#!/bin/bash
# è³‡æ–™æ¢å¾©è…³æœ¬

set -e

if [ $# -eq 0 ]; then
    echo "ä½¿ç”¨æ–¹æ³•: $0 <å‚™ä»½åç¨±>"
    echo "å¯ç”¨å‚™ä»½:"
    ls -1 "{self.backup_dir}"
    exit 1
fi

BACKUP_NAME="$1"
BACKUP_PATH="{self.backup_dir}/$BACKUP_NAME"
DATA_DIR="{self.deployment_dir}/data"
CONFIG_DIR="{self.deployment_dir}/config"

if [ ! -d "$BACKUP_PATH" ]; then
    echo "âŒ å‚™ä»½ä¸å­˜åœ¨: $BACKUP_PATH"
    exit 1
fi

echo "é–‹å§‹æ¢å¾©å‚™ä»½: $BACKUP_NAME"

# åœæ­¢æœå‹™
{self.deployment_dir}/scripts/stop.sh

# å‚™ä»½ç•¶å‰è³‡æ–™
CURRENT_BACKUP="{self.backup_dir}/current_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$CURRENT_BACKUP"
[ -d "$DATA_DIR" ] && cp -r "$DATA_DIR" "$CURRENT_BACKUP/"
[ -d "$CONFIG_DIR" ] && cp -r "$CONFIG_DIR" "$CURRENT_BACKUP/"

# æ¢å¾©è³‡æ–™
if [ -d "$BACKUP_PATH/data" ]; then
    rm -rf "$DATA_DIR"
    cp -r "$BACKUP_PATH/data" "$DATA_DIR"
    echo "âœ… è³‡æ–™æ¢å¾©å®Œæˆ"
fi

# æ¢å¾©é…ç½®
if [ -d "$BACKUP_PATH/config" ]; then
    rm -rf "$CONFIG_DIR"
    cp -r "$BACKUP_PATH/config" "$CONFIG_DIR"
    echo "âœ… é…ç½®æ¢å¾©å®Œæˆ"
fi

echo "æ¢å¾©å®Œæˆï¼Œç•¶å‰è³‡æ–™å·²å‚™ä»½è‡³: $CURRENT_BACKUP"
echo "è«‹æ‰‹å‹•é‡å•Ÿæœå‹™: {self.deployment_dir}/scripts/start.sh"
""")
        restore_script.chmod(0o755)
        
        # å»ºç«‹å®šæœŸå‚™ä»½çš„ cron ä»»å‹™ç¯„ä¾‹
        cron_example = self.deployment_dir / "scripts" / "cron_backup_example.txt"
        cron_example.write_text(f"""# å®šæœŸå‚™ä»½ cron ä»»å‹™ç¯„ä¾‹
# æ¯å¤©å‡Œæ™¨ 2 é»åŸ·è¡Œå‚™ä»½
0 2 * * * {self.deployment_dir}/scripts/backup.sh

# æ¯é€±æ—¥å‡Œæ™¨ 3 é»åŸ·è¡Œå®Œæ•´å‚™ä»½
0 3 * * 0 {self.deployment_dir}/scripts/backup.sh

# å®‰è£æ–¹æ³•:
# crontab -e
# ç„¶å¾Œæ·»åŠ ä¸Šè¿°è¡Œ
""")
        
        logger.info("âœ… å‚™ä»½å’Œæ¢å¾©æ©Ÿåˆ¶è¨­å®šå®Œæˆ")
    
    def _rollback_deployment(self):
        """å›æ»¾éƒ¨ç½²"""
        logger.warning("ğŸ”„ åŸ·è¡Œéƒ¨ç½²å›æ»¾")
        
        try:
            if self.deployment_dir.exists():
                # å»ºç«‹å¤±æ•—éƒ¨ç½²çš„å‚™ä»½
                failed_deployment_backup = self.backup_dir / f"failed_deployment_{int(time.time())}"
                shutil.move(str(self.deployment_dir), str(failed_deployment_backup))
                logger.info(f"å¤±æ•—çš„éƒ¨ç½²å·²å‚™ä»½è‡³: {failed_deployment_backup}")
            
            logger.info("âœ… éƒ¨ç½²å›æ»¾å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ éƒ¨ç½²å›æ»¾å¤±æ•—: {e}")


@click.command()
@click.option("--config", type=click.Path(exists=True), default="deployment_config.yaml",
              help="éƒ¨ç½²é…ç½®æª”æ¡ˆ")
@click.option("--deployment-dir", type=click.Path(), default="./deployment",
              help="éƒ¨ç½²ç›®éŒ„")
@click.option("--backup-dir", type=click.Path(), default="./backups",
              help="å‚™ä»½ç›®éŒ„")
@click.option("--dry-run", is_flag=True, help="æ¨¡æ“¬åŸ·è¡Œï¼ˆä¸å¯¦éš›éƒ¨ç½²ï¼‰")
@click.option("--verbose", "-v", is_flag=True, help="è©³ç´°è¼¸å‡º")
def main(config: str, deployment_dir: str, backup_dir: str, dry_run: bool, verbose: bool):
    """åŸ·è¡Œç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²"""
    
    # è¼‰å…¥éƒ¨ç½²é…ç½®
    try:
        with open(config, 'r', encoding='utf-8') as f:
            deployment_config = yaml.safe_load(f)
    except FileNotFoundError:
        # ä½¿ç”¨é è¨­é…ç½®
        deployment_config = {
            "deployment_dir": deployment_dir,
            "backup_dir": backup_dir,
            "required_disk_space_gb": 10,
            "required_memory_gb": 4,
            "test_urls": ["https://www.google.com"],
            "required_commands": ["git", "curl"],
            "production_config": {
                "workers": 4,
                "log_level": "INFO"
            }
        }
        
        # å»ºç«‹é è¨­é…ç½®æª”æ¡ˆ
        with open(config, 'w', encoding='utf-8') as f:
            yaml.dump(deployment_config, f, default_flow_style=False, allow_unicode=True)
        
        logger.info(f"å·²å»ºç«‹é è¨­é…ç½®æª”æ¡ˆ: {config}")
    
    # æ›´æ–°é…ç½®
    deployment_config.update({
        "deployment_dir": deployment_dir,
        "backup_dir": backup_dir
    })
    
    if dry_run:
        logger.info("ğŸ” æ¨¡æ“¬åŸ·è¡Œæ¨¡å¼")
        logger.info(f"éƒ¨ç½²é…ç½®: {deployment_config}")
        logger.info("å¯¦éš›éƒ¨ç½²è«‹ç§»é™¤ --dry-run åƒæ•¸")
        return
    
    # åŸ·è¡Œéƒ¨ç½²
    deployer = ProductionDeployer(deployment_config)
    success = deployer.deploy()
    
    if success:
        logger.success("ğŸ‰ ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²æˆåŠŸï¼")
        logger.info(f"éƒ¨ç½²ç›®éŒ„: {deployment_dir}")
        logger.info(f"å•Ÿå‹•å‘½ä»¤: {deployment_dir}/scripts/start.sh")
        sys.exit(0)
    else:
        logger.error("âŒ ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²å¤±æ•—ï¼")
        sys.exit(1)


if __name__ == "__main__":
    main()