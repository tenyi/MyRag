#!/usr/bin/env python3
"""
ç°¡å–®çš„æ•ˆèƒ½å„ªåŒ–åŠŸèƒ½æ¸¬è©¦
"""

import asyncio
import tempfile
from pathlib import Path

# æ¸¬è©¦å¿«å–åŠŸèƒ½
async def test_cache():
    print("æ¸¬è©¦å¿«å–åŠŸèƒ½...")
    
    from chinese_graphrag.embeddings.cache import MemoryCache, CacheEntry
    import numpy as np
    import time
    
    # å»ºç«‹è¨˜æ†¶é«”å¿«å–
    cache = MemoryCache(max_size_mb=10)
    
    # å»ºç«‹æ¸¬è©¦è³‡æ–™
    embeddings = np.random.rand(5, 768).astype(np.float32)
    texts = [f"æ¸¬è©¦æ–‡æœ¬ {i}" for i in range(5)]
    
    entry = CacheEntry(
        key="test_key",
        embeddings=embeddings,
        texts=texts,
        model_name="test_model",
        timestamp=time.time()
    )
    
    # æ¸¬è©¦å­˜å…¥
    success = await cache.put("test_key", entry)
    print(f"  å­˜å…¥çµæœ: {success}")
    
    # æ¸¬è©¦å–å¾—
    retrieved = await cache.get("test_key")
    print(f"  å–å¾—çµæœ: {retrieved is not None}")
    
    if retrieved:
        print(f"  å‘é‡å½¢ç‹€: {retrieved.embeddings.shape}")
        print(f"  æ–‡æœ¬æ•¸é‡: {len(retrieved.texts)}")
    
    # æ¸¬è©¦çµ±è¨ˆ
    stats = await cache.get_stats()
    print(f"  å¿«å–çµ±è¨ˆ: æ¢ç›®æ•¸={stats['entry_count']}, å‘½ä¸­ç‡={stats['hit_rate']:.1%}")
    
    print("âœ“ å¿«å–åŠŸèƒ½æ¸¬è©¦å®Œæˆ")


def test_device_manager():
    print("æ¸¬è©¦è£ç½®ç®¡ç†...")
    
    from chinese_graphrag.embeddings.gpu_acceleration import DeviceManager
    
    manager = DeviceManager()
    
    print(f"  å¯ç”¨è£ç½®: {manager.available_devices}")
    
    # å–å¾—æœ€ä½³è£ç½®
    device = manager.get_optimal_device(prefer_gpu=False)
    print(f"  æ¨è–¦è£ç½®: {device}")
    
    # è£ç½®è³‡è¨Š
    info = manager.get_device_info(device)
    print(f"  è£ç½®é¡å‹: {info.get('type', 'unknown')}")
    
    print("âœ“ è£ç½®ç®¡ç†æ¸¬è©¦å®Œæˆ")


def test_memory_optimizer():
    print("æ¸¬è©¦è¨˜æ†¶é«”å„ªåŒ–...")
    
    from chinese_graphrag.embeddings.gpu_acceleration import MemoryOptimizer
    
    optimizer = MemoryOptimizer(enable_auto_cleanup=False)
    
    # å–å¾—è¨˜æ†¶é«”çµ±è¨ˆ
    stats = optimizer.get_memory_stats()
    print(f"  ç³»çµ±è¨˜æ†¶é«”: {stats.system_used}/{stats.system_total} MB ({stats.system_usage_ratio:.1%})")
    print(f"  ç¨‹åºè¨˜æ†¶é«”: {stats.process_used} MB")
    
    print("âœ“ è¨˜æ†¶é«”å„ªåŒ–æ¸¬è©¦å®Œæˆ")


def test_usage_monitor():
    print("æ¸¬è©¦ä½¿ç”¨é‡ç›£æ§...")
    
    from chinese_graphrag.embeddings.monitoring import UsageMonitor
    import tempfile
    
    with tempfile.TemporaryDirectory() as temp_dir:
        monitor = UsageMonitor(
            storage_dir=temp_dir,
            enable_alerts=False
        )
        
        # è¨˜éŒ„ä¸€äº›ä½¿ç”¨é‡
        monitor.record_usage(
            model_name="test_model",
            operation="embed_texts",
            input_count=10,
            processing_time=1.0,
            success=True
        )
        
        monitor.record_usage(
            model_name="test_model",
            operation="embed_texts",
            input_count=5,
            processing_time=0.5,
            success=True
        )
        
        # å–å¾—çµ±è¨ˆ
        stats = monitor.get_model_stats("test_model")
        print(f"  æ¨¡å‹çµ±è¨ˆ: è«‹æ±‚æ•¸={stats.total_requests}, æˆåŠŸç‡={stats.success_rate:.1%}")
        print(f"  å¹³å‡è™•ç†æ™‚é–“: {stats.average_processing_time:.3f}s")
        
        # å–å¾—æ‘˜è¦
        summary = monitor.get_usage_summary(time_range_hours=1)
        print(f"  ä½¿ç”¨é‡æ‘˜è¦: ç¸½è«‹æ±‚={summary['summary']['total_requests']}")
    
    print("âœ“ ä½¿ç”¨é‡ç›£æ§æ¸¬è©¦å®Œæˆ")


async def test_embedding_manager():
    print("æ¸¬è©¦ EmbeddingManager æ•´åˆ...")
    
    from chinese_graphrag.embeddings import EmbeddingManager
    from unittest.mock import Mock
    import numpy as np
    
    # å»ºç«‹å¸¶å„ªåŒ–åŠŸèƒ½çš„ç®¡ç†å™¨
    with tempfile.TemporaryDirectory() as temp_dir:
        manager = EmbeddingManager(
            enable_cache=True,
            cache_config={"cache_dir": temp_dir, "memory_cache_mb": 10},
            enable_gpu_acceleration=True,
            enable_monitoring=True
        )
        
        # å»ºç«‹æ¨¡æ“¬æœå‹™
        mock_service = Mock()
        mock_service.model_name = "mock_model"
        mock_service.is_loaded = True
        mock_service.device = "cpu"
        
        async def mock_embed_texts(texts, normalize=True, show_progress=False):
            await asyncio.sleep(0.01)
            embeddings = np.random.rand(len(texts), 768).astype(np.float32)
            from chinese_graphrag.embeddings.base import EmbeddingResult
            return EmbeddingResult(
                embeddings=embeddings,
                texts=texts,
                model_name="mock_model",
                dimensions=768,
                processing_time=0.01
            )
        
        mock_service.embed_texts = mock_embed_texts
        manager.register_service("mock", mock_service, set_as_default=True)
        
        # æ¸¬è©¦å‘é‡åŒ–
        texts = ["æ¸¬è©¦æ–‡æœ¬1", "æ¸¬è©¦æ–‡æœ¬2"]
        result = await manager.embed_texts(texts)
        
        print(f"  å‘é‡åŒ–çµæœ: å½¢ç‹€={result.embeddings.shape}")
        print(f"  è™•ç†æ™‚é–“: {result.processing_time:.3f}s")
        
        # æ¸¬è©¦å¿«å–çµ±è¨ˆ
        cache_stats = await manager.get_cache_stats()
        if cache_stats:
            print(f"  å¿«å–çµ±è¨ˆ: é¡å‹={cache_stats.get('cache_type', 'unknown')}")
        
        # æ¸¬è©¦ä½¿ç”¨é‡çµ±è¨ˆ
        usage_stats = manager.get_usage_stats(time_range_hours=1)
        if usage_stats:
            print(f"  ä½¿ç”¨é‡çµ±è¨ˆ: è«‹æ±‚æ•¸={usage_stats['summary']['total_requests']}")
    
    print("âœ“ EmbeddingManager æ•´åˆæ¸¬è©¦å®Œæˆ")


async def main():
    print("ğŸ§ª Embedding æ•ˆèƒ½å„ªåŒ–åŠŸèƒ½ç°¡å–®æ¸¬è©¦")
    print("=" * 40)
    
    try:
        # æ¸¬è©¦å„å€‹æ¨¡çµ„
        await test_cache()
        print()
        
        test_device_manager()
        print()
        
        test_memory_optimizer()
        print()
        
        test_usage_monitor()
        print()
        
        await test_embedding_manager()
        print()
        
        print("=" * 40)
        print("âœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())