{"timestamp": 1754097183.83449, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097191.281748, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097231.7457762, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097231.745913, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097231.745982, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097231.74604, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097231.746099, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097231.7461572, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097238.6016178, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097238.601822, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097238.601899, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097238.601963, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097238.6020238, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097238.602085, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097274.951804, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097274.9520938, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097274.952194, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097274.952266, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097274.952329, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097274.952388, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097282.1323788, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097282.1325068, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097282.132571, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097282.1326442, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097282.132698, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097282.132751, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097308.365149, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097308.36532, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097308.36539, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097308.3654668, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097308.365526, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097308.365581, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097316.05718, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097316.057364, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097316.057434, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097316.0574982, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097316.057555, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097316.0576131, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097337.911808, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097337.912182, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097337.912321, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097337.912388, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097337.9124491, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097337.912508, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097345.599564, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097345.5997, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097345.599766, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097345.599825, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097345.599882, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097345.599941, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100330.429305, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100330.429636, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100330.429832, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100330.430006, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100330.430175, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100330.430364, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100931.0438578, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100931.0442612, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100931.044485, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100931.044668, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100931.044927, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100931.045328, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101756.329661, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101756.329872, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101756.3299909, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101756.330097, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101756.3302011, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101756.330741, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101845.841852, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101853.149666, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101885.371962, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101898.4990358, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101905.830134, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101920.625152, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102254.8771892, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102254.8773592, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102254.877472, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102254.877573, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102254.877662, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102254.87775, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102258.783672, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102517.343467, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102517.343651, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102517.343772, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102517.343874, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102517.3439739, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102517.344067, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102521.263499, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754103940.084358, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754103940.0845308, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754103940.0846379, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754103940.0847402, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754103940.084832, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754103940.084927, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754103943.976011, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754104708.124802, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754104708.125269, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754104708.1255229, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754104708.1257331, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754104708.125924, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754104708.126109, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754104712.09619, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754105633.375655, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754105633.375821, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754105633.375934, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754105633.3760278, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754105633.37612, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754105633.376228, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754105637.258508, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106265.069567, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106326.7404642, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106449.054881, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106449.055231, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106449.055419, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106449.055584, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106449.055682, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106449.055773, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106452.943048, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106818.786889, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106818.787193, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106818.787358, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106818.78751, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106818.787654, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106818.787792, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106822.712139, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754107484.56955, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754107484.569778, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754107484.5698938, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754107484.569994, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754107484.57009, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754107484.570184, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754107488.5017972, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754111104.2761972, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754111104.276564, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754111104.2768052, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754111104.277026, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754111104.277245, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754111104.2774541, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754111108.198868, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114517.923886, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114531.5225759, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114593.435529, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114778.313023, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114778.3133829, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114778.313613, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114778.313813, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114778.314006, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114778.314198, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114782.243712, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114876.409714, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114876.410072, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114876.4102678, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114876.410444, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114876.410607, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114876.4107652, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114880.346387, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114921.733033, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114921.733191, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114921.7333, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114921.73339, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114921.73348, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114921.733566, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754114925.6757262, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754115014.368812, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116841.56119, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116882.010377, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116882.010592, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116882.010716, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116882.010823, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116882.010939, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116882.011036, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116885.931079, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116936.1742668, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116936.1745138, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116936.174641, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116936.17474, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116936.174835, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116936.174931, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754116940.083888, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754117365.435335, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754117365.435769, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754117365.4360452, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754117365.43628, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754117365.436502, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754117365.436716, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754117369.3732128, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754117636.007974, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754117636.00819, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754117636.0082932, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754117636.0083892, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754117636.0084789, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754117636.008568, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754117639.940924, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754118370.795188, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754118370.79546, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754118370.7956421, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754118370.795806, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754118370.795996, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754118370.796179, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754118374.720948, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
