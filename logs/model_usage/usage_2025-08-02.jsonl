{"timestamp": 1754097183.83449, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097191.281748, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097231.7457762, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097231.745913, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097231.745982, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097231.74604, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097231.746099, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097231.7461572, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097238.6016178, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097238.601822, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097238.601899, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097238.601963, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097238.6020238, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097238.602085, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097274.951804, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097274.9520938, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097274.952194, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097274.952266, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097274.952329, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097274.952388, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097282.1323788, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097282.1325068, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097282.132571, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097282.1326442, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097282.132698, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097282.132751, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097308.365149, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097308.36532, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097308.36539, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097308.3654668, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097308.365526, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097308.365581, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097316.05718, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097316.057364, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097316.057434, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097316.0574982, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097316.057555, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097316.0576131, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097337.911808, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097337.912182, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097337.912321, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097337.912388, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097337.9124491, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097337.912508, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097345.599564, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097345.5997, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097345.599766, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097345.599825, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097345.599882, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754097345.599941, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100330.429305, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100330.429636, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100330.429832, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100330.430006, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100330.430175, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100330.430364, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100931.0438578, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100931.0442612, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100931.044485, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100931.044668, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100931.044927, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754100931.045328, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101756.329661, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101756.329872, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101756.3299909, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101756.330097, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101756.3302011, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101756.330741, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101845.841852, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101853.149666, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101885.371962, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101898.4990358, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101905.830134, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754101920.625152, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102254.8771892, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102254.8773592, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102254.877472, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102254.877573, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102254.877662, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102254.87775, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102258.783672, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102517.343467, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102517.343651, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102517.343772, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102517.343874, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102517.3439739, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102517.344067, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754102521.263499, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754103940.084358, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754103940.0845308, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754103940.0846379, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754103940.0847402, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754103940.084832, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754103940.084927, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754103943.976011, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754104708.124802, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754104708.125269, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754104708.1255229, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754104708.1257331, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754104708.125924, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754104708.126109, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754104712.09619, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754105633.375655, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754105633.375821, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754105633.375934, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754105633.3760278, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754105633.37612, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754105633.376228, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754105637.258508, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106265.069567, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106326.7404642, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106449.054881, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106449.055231, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106449.055419, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106449.055584, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106449.055682, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106449.055773, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106452.943048, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106818.786889, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106818.787193, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106818.787358, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106818.78751, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106818.787654, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106818.787792, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754106822.712139, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754107484.56955, "model_name": "gpt-3.5-turbo", "model_type": "llm", "task_type": "embedding", "input_tokens": 1000, "output_tokens": 0, "total_tokens": 1000, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754107484.569778, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 500, "output_tokens": 0, "total_tokens": 500, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754107484.5698938, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 600, "output_tokens": 0, "total_tokens": 600, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754107484.569994, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 700, "output_tokens": 0, "total_tokens": 700, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754107484.57009, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 800, "output_tokens": 0, "total_tokens": 800, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754107484.570184, "model_name": "gpt-4", "model_type": "llm", "task_type": "query", "input_tokens": 900, "output_tokens": 0, "total_tokens": 900, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
{"timestamp": 1754107488.5017972, "model_name": "test-model", "model_type": "llm", "task_type": "query", "input_tokens": 100, "output_tokens": 0, "total_tokens": 100, "cost": 0.0, "latency_ms": 0.0, "quality_score": 0.0, "success": true, "error_message": null}
